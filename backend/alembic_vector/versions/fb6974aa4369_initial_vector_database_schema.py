"""initial vector database schema

Revision ID: fb6974aa4369
Revises: 
Create Date: 2025-07-31 01:48:43.304421

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
from pgvector.sqlalchemy import Vector

# revision identifiers, used by Alembic.
revision = 'fb6974aa4369'
down_revision = None
branch_labels = None
depends_on = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    # Install pgvector extension
    op.execute('CREATE EXTENSION IF NOT EXISTS vector')
    op.create_table('cluster_results',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('algorithm', sa.Text(), nullable=False),
    sa.Column('cluster_count', sa.Integer(), nullable=False),
    sa.Column('parameters', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('silhouette_score', sa.Float(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('success_conversation_vectors',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('session_id', sa.Text(), nullable=False),
    sa.Column('chunk_text', sa.Text(), nullable=False),
    sa.Column('embedding', Vector(1536), nullable=False),
    sa.Column('chunk_metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('chunk_index', sa.Integer(), nullable=False),
    sa.Column('counselor_name', sa.Text(), nullable=True),
    sa.Column('is_success', sa.Boolean(), nullable=True),
    sa.Column('session_metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('anomaly_detection_results',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('vector_id', sa.UUID(), nullable=False),
    sa.Column('algorithm', sa.Text(), nullable=False),
    sa.Column('anomaly_score', sa.Float(), nullable=False),
    sa.Column('is_anomaly', sa.Boolean(), nullable=False),
    sa.Column('parameters', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['vector_id'], ['success_conversation_vectors.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('cluster_assignments',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('vector_id', sa.UUID(), nullable=False),
    sa.Column('cluster_result_id', sa.UUID(), nullable=False),
    sa.Column('cluster_label', sa.Integer(), nullable=False),
    sa.Column('distance_to_centroid', sa.Float(), nullable=True),
    sa.ForeignKeyConstraint(['cluster_result_id'], ['cluster_results.id'], ),
    sa.ForeignKeyConstraint(['vector_id'], ['success_conversation_vectors.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('cluster_representatives',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('cluster_result_id', sa.UUID(), nullable=False),
    sa.Column('vector_id', sa.UUID(), nullable=False),
    sa.Column('cluster_label', sa.Integer(), nullable=False),
    sa.Column('quality_score', sa.Float(), nullable=False),
    sa.Column('distance_to_centroid', sa.Float(), nullable=False),
    sa.Column('is_primary', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['cluster_result_id'], ['cluster_results.id'], ),
    sa.ForeignKeyConstraint(['vector_id'], ['success_conversation_vectors.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('cluster_representatives')
    op.drop_table('cluster_assignments')
    op.drop_table('anomaly_detection_results')
    op.drop_table('success_conversation_vectors')
    op.drop_table('cluster_results')
    # ### end Alembic commands ###